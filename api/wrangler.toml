# wrangler.toml — Cognomega API Worker (prod, merged with former auth worker config)

name               = "cognomega-api"
main               = "src/index.ts"
compatibility_date = "2025-09-03"
workers_dev        = false
# logpush          = true   # optional

# Route *everything* under api.cognomega.com to this Worker
routes = [
  { pattern = "api.cognomega.com/*", zone_name = "cognomega.com" }
]

# --- Bindings ---

# Cloudflare Workers AI
[ai]
binding = "AI"

# KV namespaces (from auth)
[[kv_namespaces]]
binding = "KEYS"         # public JWKS (key: "jwks")
id      = "7e9d002852ba44849900a2babfcaf816"

[[kv_namespaces]]
binding = "KV_BILLING"   # credits + usage + jobs
id      = "5da314a8b48b4db684678ab5ad074563"

# R2 buckets
# Keep BOTH: legacy code may use R2, new code uses R2_UPLOADS.
[[r2_buckets]]
binding     = "R2"                 # existing bucket your API used
bucket_name = "cognomega-prod"

[[r2_buckets]]
binding     = "R2_UPLOADS"         # used by the imported auth/billing module
bucket_name = "cognomega-uploads"

# --- Vars (non-secrets) brought over from auth ---

[vars]
# CORS / JWT / Credits
CREDIT_PER_1K    = "0.05"                     # credits per 1k tokens
ALLOWED_ORIGINS  = "https://app.cognomega.com"
JWT_TTL_SEC      = "3600"
ISSUER           = "https://api.cognomega.com"
KID              = "k1"

# Provider order & model defaults
PREFERRED_PROVIDER = "groq,cfai,openai"

GROQ_MODEL   = "llama-3.1-8b-instant"
CF_AI_MODEL  = "@cf/meta/llama-3.1-8b-instruct"
OPENAI_MODEL = "gpt-4o-mini"
OPENAI_BASE  = "https://api.openai.com/v1"

# Optional (uncomment if you want to override)
# GROQ_BASE        = "https://api.groq.com/openai/v1"
# MAX_UPLOAD_BYTES = "10485760"    # 10MB

# --- Scheduled tasks (you already had this; keep as-is) ---
[triggers]
crons = ["*/5 * * * *"]
